{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0f26fa",
   "metadata": {},
   "source": [
    "# Learning Probability Density Functions using Data Only (GAN)\n",
    "\n",
    "**Student:** Rohan Malhotra  \n",
    "**Roll Number:** 102303437  \n",
    "\n",
    "This notebook:\n",
    "1. Loads NO₂ concentration data `x`\n",
    "2. Transforms it to `z = x + a_r sin(b_r x)`\n",
    "3. Trains a 1D GAN on samples of `z` only\n",
    "4. Generates samples from the trained generator\n",
    "5. Approximates the PDF using histogram and KDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70576314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed, uncomment to install dependencies\n",
    "# !pip install pandas numpy matplotlib scikit-learn torch --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ee86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00cfb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLL_NUMBER = 102303437\n",
    "\n",
    "a_r = 0.5 * (ROLL_NUMBER % 7)\n",
    "b_r = 0.3 * ((ROLL_NUMBER % 5) + 1)\n",
    "\n",
    "print('ROLL_NUMBER =', ROLL_NUMBER)\n",
    "print('a_r =', a_r)\n",
    "print('b_r =', b_r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f5389",
   "metadata": {},
   "source": [
    "## Load Dataset (NO₂ as feature x)\n",
    "\n",
    "Download the Kaggle CSV and update `CSV_PATH`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69328c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = 'india_air_quality_data.csv'  # <- change this\n",
    "\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(f'File not found: {CSV_PATH}. Download Kaggle CSV and update CSV_PATH.')\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print('Shape:', df.shape)\n",
    "print('Columns:', list(df.columns))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa55e9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect NO2 column (case-insensitive)\n",
    "cands = [c for c in df.columns if 'no2' in str(c).strip().lower() or str(c).strip().lower() in {'no₂'}]\n",
    "print('Candidates:', cands)\n",
    "\n",
    "if not cands:\n",
    "    raise ValueError('No NO2 column found automatically. Set NO2_COL manually after checking df.columns.')\n",
    "\n",
    "NO2_COL = cands[0]\n",
    "print('Using NO2_COL =', NO2_COL)\n",
    "\n",
    "x = pd.to_numeric(df[NO2_COL], errors='coerce').dropna().values.astype(np.float32)\n",
    "x = x[np.isfinite(x)]\n",
    "\n",
    "print('Valid samples:', len(x))\n",
    "print('x min/max/mean:', float(np.min(x)), float(np.max(x)), float(np.mean(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f242d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform x -> z\n",
    "z = (x + a_r * np.sin(b_r * x)).astype(np.float32)\n",
    "\n",
    "print('z min/max/mean:', float(np.min(z)), float(np.max(z)), float(np.mean(z)))\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(x, bins=60, density=True)\n",
    "plt.title('Original x (NO2)')\n",
    "plt.xlabel('x'); plt.ylabel('Density')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(z, bins=60, density=True)\n",
    "plt.title('Transformed z')\n",
    "plt.xlabel('z'); plt.ylabel('Density')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857583d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize z for stable GAN training\n",
    "z_mean, z_std = z.mean(), z.std() + 1e-8\n",
    "z_norm = ((z - z_mean) / z_std).reshape(-1, 1)\n",
    "\n",
    "batch_size = 128\n",
    "loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(z_norm, dtype=torch.float32)),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print('Normalized z mean/std:', float(z_norm.mean()), float(z_norm.std()))\n",
    "print('Batches per epoch:', len(loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a3372",
   "metadata": {},
   "source": [
    "## GAN Architecture (1D MLP GAN)\n",
    "\n",
    "- **Generator:** noise \\(\\epsilon \\sim N(0,1)\\) → scalar fake sample\n",
    "- **Discriminator:** scalar sample → probability real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f193b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 8\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=LATENT_DIM):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(32, 64), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(64, 32), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, z): return self.net(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, 32), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(32, 64), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(64, 32), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(32, 1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "print(G)\n",
    "print(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc936cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "epochs = 300\n",
    "lr = 1e-4\n",
    "criterion = nn.BCELoss()\n",
    "g_opt = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "d_opt = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "g_losses, d_losses = [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GAN\n",
    "for epoch in range(1, epochs + 1):\n",
    "    g_epoch = 0.0\n",
    "    d_epoch = 0.0\n",
    "    for (real_batch,) in loader:\n",
    "        real_batch = real_batch.to(device)\n",
    "        bs = real_batch.size(0)\n",
    "\n",
    "        # Train D\n",
    "        d_opt.zero_grad()\n",
    "        real_y = torch.full((bs, 1), 0.9, device=device)  # label smoothing\n",
    "        fake_y = torch.zeros((bs, 1), device=device)\n",
    "\n",
    "        real_pred = D(real_batch)\n",
    "        d_real_loss = criterion(real_pred, real_y)\n",
    "\n",
    "        noise = torch.randn(bs, LATENT_DIM, device=device)\n",
    "        fake_batch = G(noise).detach()\n",
    "        fake_pred = D(fake_batch)\n",
    "        d_fake_loss = criterion(fake_pred, fake_y)\n",
    "\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        d_opt.step()\n",
    "\n",
    "        # Train G\n",
    "        g_opt.zero_grad()\n",
    "        noise = torch.randn(bs, LATENT_DIM, device=device)\n",
    "        gen_batch = G(noise)\n",
    "        gen_pred = D(gen_batch)\n",
    "        g_loss = criterion(gen_pred, torch.ones((bs,1), device=device))\n",
    "        g_loss.backward()\n",
    "        g_opt.step()\n",
    "\n",
    "        d_epoch += d_loss.item()\n",
    "        g_epoch += g_loss.item()\n",
    "\n",
    "    d_epoch /= max(1, len(loader))\n",
    "    g_epoch /= max(1, len(loader))\n",
    "    d_losses.append(d_epoch)\n",
    "    g_losses.append(g_epoch)\n",
    "\n",
    "    if epoch % 25 == 0 or epoch == 1:\n",
    "        print(f'Epoch {epoch}/{epochs} | D={d_epoch:.4f} | G={g_epoch:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1eb658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loss plot\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(d_losses, label='D loss')\n",
    "plt.plot(g_losses, label='G loss')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
    "plt.title('GAN Training Losses')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624774d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples from G and map back to original z scale\n",
    "G.eval()\n",
    "n_gen = 50000\n",
    "\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(n_gen, LATENT_DIM, device=device)\n",
    "    zf_norm = G(noise).cpu().numpy().reshape(-1)\n",
    "\n",
    "zf = (zf_norm * z_std) + z_mean\n",
    "\n",
    "print('Generated z_f min/max/mean:', float(np.min(zf)), float(np.max(zf)), float(np.mean(zf)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c5e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE-based PDF approximation p_h(z) from generated samples\n",
    "grid = np.linspace(min(z.min(), zf.min()), max(z.max(), zf.max()), 1000).reshape(-1,1)\n",
    "\n",
    "bandwidth = max(0.05, 0.15 * float(np.std(z)))\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth)\n",
    "kde.fit(zf.reshape(-1,1))\n",
    "logp = kde.score_samples(grid)\n",
    "ph = np.exp(logp)\n",
    "\n",
    "print('KDE bandwidth:', bandwidth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcdce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final PDF plot (real vs generated + KDE estimate)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(z, bins=80, density=True, alpha=0.35, label='Real z (hist)')\n",
    "plt.hist(zf, bins=80, density=True, alpha=0.35, label='Generated z_f (hist)')\n",
    "plt.plot(grid.squeeze(), ph, linewidth=2, label='Estimated PDF p_h(z) from GAN samples (KDE)')\n",
    "plt.xlabel('z'); plt.ylabel('Density')\n",
    "plt.title('PDF Approximation of Transformed Variable z using GAN')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89857d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: save artifacts for README/report\n",
    "# plt.savefig('gan_pdf_plot.png', dpi=200)\n",
    "# pd.DataFrame({'epoch': np.arange(1, len(d_losses)+1), 'd_loss': d_losses, 'g_loss': g_losses}).to_csv('training_losses.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b6445",
   "metadata": {},
   "source": [
    "## Observations (fill after execution)\n",
    "Comment on:\n",
    "- Mode coverage\n",
    "- Training stability\n",
    "- Quality of generated distribution\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
